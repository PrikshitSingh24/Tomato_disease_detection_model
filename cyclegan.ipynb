{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import tensorflow_addons as tfa\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [512, 512]\n",
    "INPUT_SIZE = [256, 256] #just for fast training\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def data_pipeline(filenames, label_num, batch_size, is_train=True):\n",
    "    label_num = tf.constant(label_num, tf.int32)\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.filter(lambda x, y: y == label_num)# only seletcted label number can go through\n",
    "    dataset = dataset.map(lambda x, y: x, num_parallel_calls=AUTO)# do not use label\n",
    "    if is_train:\n",
    "        dataset = dataset.map(data_augmentation, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.shuffle(64)\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.map(resize_and_normalize, num_parallel_calls=AUTO)   \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    img = decode_img(example['image'])\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    return img, label\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.reshape(img, [*IMAGE_SIZE, 3])\n",
    "    return img\n",
    "\n",
    "def data_augmentation(img):\n",
    "    # horizontal flip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = img[:, ::-1, :]\n",
    "    \n",
    "    # vertical flip\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = img[::-1, :, :]\n",
    "        \n",
    "    # random crop\n",
    "    if tf.random.uniform(()) > 0.3:\n",
    "        height = tf.random.uniform(shape=(), minval=450, maxval=500)\n",
    "        width = tf.random.uniform(shape=(), minval=450, maxval=500)\n",
    "        img = tf.image.random_crop(img, [height,width,3])\n",
    "    \n",
    "    # change brightness and contrast\n",
    "    contrast_rate = tf.random.uniform(shape=(), minval=0.8, maxval=1.2)\n",
    "    img = tf.image.adjust_contrast(img, contrast_rate)\n",
    "\n",
    "    brightness_shift = tf.random.uniform(shape=(), minval=-20, maxval=20)\n",
    "    img = tf.image.adjust_brightness(img, brightness_shift)\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "\n",
    "    # change hue\n",
    "    hue_rate = tf.random.uniform(shape=(), minval=-0.05, maxval=0.05)\n",
    "    img = tf.image.adjust_hue(img, hue_rate)\n",
    "\n",
    "    return img\n",
    "      \n",
    "def resize_and_normalize(img):\n",
    "    img = img[tf.newaxis, ...]\n",
    "    img = tf.image.resize(img, tuple(INPUT_SIZE))[0,:,:,:]\n",
    "    img = (img/127.5) - 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan_models():\n",
    "    generator_x2y = build_generator()\n",
    "    generator_y2x = build_generator()\n",
    "    discriminator_x = build_discriminator()\n",
    "    discriminator_y = build_discriminator()\n",
    "    return generator_x2y, generator_y2x, discriminator_x, discriminator_y\n",
    "\n",
    "\n",
    "def downsample(filters, size, apply_instancenorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_instancenorm:\n",
    "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def build_generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_instancenorm=False),\n",
    "        downsample(128, 4),\n",
    "        downsample(256, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "        downsample(512, 4),\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4, apply_dropout=True),\n",
    "        upsample(512, 4),\n",
    "        upsample(256, 4),\n",
    "        upsample(128, 4),\n",
    "        upsample(64, 4),\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                  strides=2,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  activation='tanh')\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "def build_discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    \n",
    "    # I use pretrained model of VGG instead of the model given in the original notebook,\n",
    "    # because this classification task is much more difficult than the original task(Monet or photo). \n",
    "    pretrained_model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False ,input_shape=[256,256, 3])\n",
    "    x = pretrained_model(inputs)\n",
    "    \"\"\"\n",
    "    \n",
    "    down1 = downsample(64, 4, False)(inputs)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                         kernel_initializer=initializer,\n",
    "                         use_bias=False)(zero_pad1)\n",
    "\n",
    "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                         kernel_initializer=initializer)(zero_pad2)\n",
    "    \"\"\"\n",
    "    last =  tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=last)\n",
    "\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    bc_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    real_loss = bc_loss(tf.ones_like(real), real)# real as real\n",
    "    generated_loss = bc_loss(tf.zeros_like(generated), generated)# fake as fake\n",
    "    #loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return (real_loss + generated_loss) * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    bc_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)# fake as real\n",
    "    return bc_loss(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return 10 * loss\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return 5 * loss\n",
    "\n",
    "\n",
    "class CycleGan(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_x2y,\n",
    "        generator_y2x,\n",
    "        discriminator_x,\n",
    "        discriminator_y,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.generator_x2y = generator_x2y\n",
    "        self.generator_y2x = generator_y2x\n",
    "        self.discriminator_x = discriminator_x\n",
    "        self.discriminator_y = discriminator_y\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        generator_x2y_optimizer,\n",
    "        generator_y2x_optimizer,\n",
    "        discriminator_x_optimizer,\n",
    "        discriminator_y_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.generator_x2y_optimizer = generator_x2y_optimizer\n",
    "        self.generator_y2x_optimizer = generator_y2x_optimizer\n",
    "        self.discriminator_x_optimizer = discriminator_x_optimizer\n",
    "        self.discriminator_y_optimizer = discriminator_y_optimizer\n",
    "        self.generator_loss = gen_loss_fn\n",
    "        self.discriminator_loss = disc_loss_fn\n",
    "        self.cycle_loss = cycle_loss_fn\n",
    "        self.identity_loss = identity_loss_fn\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        real_x, real_y = batch_data\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Generator G translates X -> Y\n",
    "            # Generator F translates Y -> X.\n",
    "\n",
    "            fake_y = self.generator_x2y(real_x, training=True)\n",
    "            cycled_x = self.generator_y2x(fake_y, training=True)\n",
    "\n",
    "            fake_x = self.generator_y2x(real_y, training=True)\n",
    "            cycled_y = self.generator_x2y(fake_x, training=True)\n",
    "\n",
    "            # same_x and same_y are used for identity loss. in half cycle, do not change original image\n",
    "            same_x = self.generator_y2x(real_x, training=True)\n",
    "            same_y = self.generator_x2y(real_y, training=True)\n",
    "\n",
    "            # discriminate 4 images in total\n",
    "            disc_real_x = self.discriminator_x(real_x, training=True)\n",
    "            disc_real_y = self.discriminator_y(real_y, training=True)\n",
    "\n",
    "            disc_fake_x = self.discriminator_x(fake_x, training=True)\n",
    "            disc_fake_y = self.discriminator_y(fake_y, training=True)\n",
    "\n",
    "            # calculate the loss\n",
    "            gen_x2y_loss = self.generator_loss(disc_fake_y)\n",
    "            gen_y2x_loss = self.generator_loss(disc_fake_x)\n",
    "\n",
    "            total_cycle_loss = self.cycle_loss(real_x, cycled_x) + self.cycle_loss(real_y, cycled_y)\n",
    "\n",
    "            # Total generator loss = adversarial loss + cycle loss\n",
    "            total_gen_x2y_loss = gen_x2y_loss + total_cycle_loss + self.identity_loss(real_y, same_y)\n",
    "            total_gen_y2x_loss = gen_y2x_loss + total_cycle_loss + self.identity_loss(real_x, same_x)\n",
    "\n",
    "            disc_x_loss = self.discriminator_loss(disc_real_x, disc_fake_x)\n",
    "            disc_y_loss = self.discriminator_loss(disc_real_y, disc_fake_y)\n",
    "      \n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        generator_x2y_gradients = tape.gradient(total_gen_x2y_loss, \n",
    "                                              self.generator_x2y.trainable_variables)\n",
    "        generator_y2x_gradients = tape.gradient(total_gen_y2x_loss, \n",
    "                                              self.generator_y2x.trainable_variables)\n",
    "        \n",
    "        discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                                  self.discriminator_x.trainable_variables)\n",
    "        discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                                  self.discriminator_y.trainable_variables)\n",
    "      \n",
    "        # Apply the gradients to the optimizer\n",
    "        self.generator_x2y_optimizer.apply_gradients(zip(generator_x2y_gradients, \n",
    "                                                  self.generator_x2y.trainable_variables))\n",
    "    \n",
    "        self.generator_y2x_optimizer.apply_gradients(zip(generator_y2x_gradients, \n",
    "                                                  self.generator_y2x.trainable_variables))\n",
    "      \n",
    "        self.discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                      self.discriminator_x.trainable_variables))\n",
    "        \n",
    "        self.discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                      self.discriminator_y.trainable_variables))\n",
    "    \n",
    "    \n",
    "        return {\n",
    "                \"gen_x2y_loss\": total_gen_x2y_loss,\n",
    "                \"gen_y2x_loss\": total_gen_y2x_loss,\n",
    "                \"disc_x_loss\": disc_x_loss,\n",
    "                \"disc_y_loss\": disc_y_loss\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "filenames = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/ld_train*.tfrec')\n",
    "CBSD_data = data_pipeline(filenames, label_num=1, batch_size=batch_size, is_train=True)\n",
    "Healthy_data = data_pipeline(filenames, label_num=4, batch_size=batch_size, is_train=True)\n",
    "\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(2,num_samples, figsize=(12,6))\n",
    "for i, data in enumerate(CBSD_data.take(num_samples)):\n",
    "    axes[0, i].imshow(data[0].numpy() * 0.5 + 0.5)\n",
    "    axes[0, i].title.set_text(\"CBSD\")\n",
    "    \n",
    "for i, data in enumerate(Healthy_data.take(num_samples)):\n",
    "    axes[1, i].imshow(data[0].numpy() * 0.5 + 0.5)\n",
    "    axes[1, i].title.set_text(\"Healthy\")    \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = 2000\n",
    "learning_rate = 1e-4\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "generator_x2y, generator_y2x, discriminator_x, discriminator_y = build_gan_models()\n",
    "\n",
    "\n",
    "# loss and learning rate\n",
    "generator_x2y_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5)\n",
    "generator_y2x_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(learning_rate/10, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(learning_rate/10, beta_1=0.5)\n",
    "\n",
    "cycle_gan_model = CycleGan(generator_x2y, generator_y2x, discriminator_x, discriminator_y)\n",
    "\n",
    "\n",
    "def compile_and_fit(epochs):\n",
    "    cycle_gan_model.compile(generator_x2y_optimizer, generator_y2x_optimizer,\n",
    "                            discriminator_x, discriminator_y,\n",
    "                            generator_loss,\n",
    "                            discriminator_loss,\n",
    "                            calc_cycle_loss,\n",
    "                            identity_loss\n",
    "                            )\n",
    "    cycle_gan_model.fit(tf.data.Dataset.zip((CBSD_data, Healthy_data)),\n",
    "                        batch_size = batch_size,\n",
    "                        steps_per_epoch = data_num//batch_size, \n",
    "                        epochs=epochs\n",
    "                        )    \n",
    "\n",
    "\n",
    "# I don't want to break the pretrained weight of disciminator at initial epochs.\n",
    "discriminator_x.trainable = False\n",
    "discriminator_y.trainable = False\n",
    "compile_and_fit(epochs=3)\n",
    "\n",
    "discriminator_x.trainable = True\n",
    "discriminator_y.trainable = True\n",
    "compile_and_fit(epochs=10)\n",
    "\n",
    "cycle_gan_model.save_weights(\"gan_10ep_CBSD_healthy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Original Image', 'Generated Image']\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for inputs in CBSD_data.take(12):\n",
    "    generate_images(generator_x2y, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in Healthy_data.take(12):\n",
    "    generate_images(generator_y2x, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLPLANT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
